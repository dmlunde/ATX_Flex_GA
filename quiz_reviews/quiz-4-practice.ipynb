{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Quiz 4 In-Class Review\n",
    "\n",
    " _**Author:** Boom D. (DSI-NYC)_\n",
    "\n",
    "---\n",
    "*Note: solutions will not be distributed as this is an in-class exercise, not a \"practice quiz\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Briefly explain the process behind how a decision tree should make its first split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will make its first split based on how well that split effectively divides the observed data, i.e., get a low gini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Consider the following scenario for Q2 - Q5)_ <br>\n",
    "\n",
    "Suppose we've written decision tree classification algorithm to predict whether or not a customer will unsubscribe from a dog lovers magazine. We classify observations into $Y = 1$ (unsubscribe) or $Y = 0$ (remain). Our training set includes 2000 observations, where we have 1000 $Y = 1$ and 1000 $Y = 0$ (i.e. perfectly balanced classes). We have two categorical features:\n",
    "- $X_1$ = whether or not the customer has a Corgi\n",
    "- $X_2$ = whether or not the customer has a Shiba Inu\n",
    "\n",
    "If $X_1$ were used as the root node, $X_1 = 1$ would lead to a split of (400 yes, 400 no), and $X_1 = 0$ would lead to a split of (600 yes, 600 no).\n",
    "\n",
    "If $X_2$ were used as the root node, $X_2 = 1$ would lead to a split of (500 yes, 600 no), and $X_2 = 0$ would lead to a split of (500 yes, 400 no)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Illustrate these scenarios using Decision Tree diagrams on the board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** For the $X_1$ tree, what are the Gini values for each of the child nodes resulting from the $X_1 = 1$ and $X_1 = 0$ splits? <br> **_YOU DO NOT NEED TO CRUNCH ANY NUMBERS!_**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** What is the Gini for the $X_1$ feature if used as the root node? Hence, what would be the Information Gain (from Gini) from using $X_1$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** Without performing any calculations, what would you expect the sign (i.e. positive, zero, or negative) for the Information Gain (from Gini) from using $X_2$ to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Explain what we mean by _bootstrapping_ and briefly outline how the process works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Sampling with Replacement. We take 1 observation from our original sample, count that towards our 'new' sample of data, and then put it back into the original sample. We then repeat the process until our 'new' sample size is appropriate for the problem/situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Consider the following scenario for Q8 - Q9)_ <br>\n",
    "Suppose we have a list of numbers `list_data = [1, 4, 7, 3, 2, 8, 2, 5, 8, 1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** Using `numpy`, write a single line of code to generate a bootstrapped sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 7, 2, 7, 2, 2, 8, 2, 4, 3])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "list_data = [1, 4, 7, 3, 2, 8, 2, 5, 8, 1]\n",
    "#np.random.seed(42)\n",
    "\n",
    "np.random.choice(list_data, size=len(list_data), replace=True)\n",
    "# Your code below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** Briefly explain how the **Bagged Decision Tree Classifier** works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple individual decision trees get created on bootstrapped samples, then we get the aggregate of all the different trees and make the classification based on the classification with the most 'votes'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9.** Briefly explain how the **Random Forest Classifier** works. In particular, be sure to address what the word \"random\" here refers to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A random forest begins (first tree overall and root node) with the best split possible out of a random subset of features. This process repeats to create many nodes on the same tree and then more decision trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.** Which of the following are ensemble methods?\n",
    "\n",
    "    I. CART\n",
    "    II. Bagging\n",
    "    III. Random Forests\n",
    "    IV. AdaBoost\n",
    "    \n",
    "(A) I, II, and III only <br>\n",
    "(B) I, III, and IV only <br>\n",
    "(C) II, III, and IV only <br>\n",
    "(D) II and III only <br>\n",
    "(E) III and IV only <br>\n",
    "(F) All of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** Describe the purpose of the kernel in the SVM algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel Trick - the purpose is to transform the observations into higher dimensions so we can linearly separate the data when before, in the lower dimension, it was not possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalized Linear Models (GLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** What kind of GLM would be most appropriate if I wanted to build a model to predict the number of customers who will walk into the Liquiteria store on 51st St and Lexington Ave in a given hour given a bunch of features on customer preferences and behavior?\n",
    "\n",
    "(A) Logistic Regression <br>\n",
    "(B) Poisson Regression <br>\n",
    "(C) Gamma Regression <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson because we're quantifying a discrete observation within a timeframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** What kind of GLM would be most appropriate if I wanted to build a model to predict the number of new Via Pass subscribers in the next month given a bunch of features on rider characteristics?\n",
    "\n",
    "(A) Logistic Regression <br>\n",
    "(B) Poisson Regression <br>\n",
    "(C) Gamma Regression <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** What kind of GLM would be most appropriate if I wanted to build a model to predict the time until Trump posts another controversial tweet given a bunch of features?\n",
    "\n",
    "(A) Logistic Regression <br>\n",
    "(B) Poisson Regression <br>\n",
    "(C) Gamma Regression <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma, time until an event, continuous distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** What kind of GLM would be most appropriate if I wanted to build a model to predict the probability that a customer unsubscribes from a magazine given a bunch of features on customer characteristics?\n",
    "\n",
    "(A) Logistic Regression <br>\n",
    "(B) Poisson Regression <br>\n",
    "(C) Gamma Regression <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q16.** I fit a model. When “fitting” the model, the computer uses gradient descent to\n",
    "estimate the parameters of the model. After fitting the model, Python returns a `ConvergenceWarning`. Discuss possible reasons why this happened and how we can remedy this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use my features to minimize an error of my choosing.\n",
    "\n",
    "ANSWER: change features, change parameters, raise max_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q17.** Explain the difference between `WHERE` and `HAVING`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They're both filters. WHERE is pretty general, similar to a Python if statement. HAVING is often used after aggregating something and using GROUPBY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_(Use the following schemata to answer questions )_\n",
    "\n",
    "Lyft acquired the rights to add CitiBike to its app as part of its Bikes & Scooters business a few months ago. You are a Data Scientist studying a `rides` table containing data on completed trips taken by riders, and a `deployed_bikes` table which contains information on the locations where each unique bike is deployed (i.e. where it is stationed).\n",
    "\n",
    "**`rides`** schema: \n",
    "- `ride_id`: int **[PRIMARY KEY]**\n",
    "- `bike_id`: int\n",
    "- `ride_date`: datetime (_You may treat this as a string in the form `YYYY-MM-DD` for this problem_)\n",
    "- `ride_hour`: int\n",
    "- `ride_min`: int\n",
    "- `ride_sec`: int\n",
    "- `duration`: int\n",
    "\n",
    "`deployed_bikes` schema:\n",
    "- `bike_id`: int **[PRIMARY KEY]**\n",
    "- `deploy_location`: string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q18.** Write a query that returns the total number of rides taken throughout the entire history available in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q19.** Write a query that returns the average length of rides taken where the user departed at the 10:00 AM hour. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT AVG(duration)\n",
    "\n",
    "FROM rides\n",
    "\n",
    "WHERE ride_hour = 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

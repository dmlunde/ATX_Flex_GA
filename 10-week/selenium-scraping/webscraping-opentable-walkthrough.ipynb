{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Webscraping OpenTable with Selenium: Guided Lab\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> *Note: this lab is intended to be instructor guided.*\n",
    "\n",
    "\n",
    "In today's codealong lab, we will build a scraper using urllib and BeautifulSoup. We will remedy some of the pitfalls of automated scraping by using a a \"headless\" browser called Selenium.\n",
    "\n",
    "You will be scraping OpenTable's Austin listings. We're interested in knowing the restaurant's **name, location, price, and how many people booked it today.**\n",
    "\n",
    "OpenTable provides all of this information on this given page: [Open table listings](https://www.opentable.com/austin-restaurant-listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Inspect the elements of this page to assure we can find each of the bits of information in which we're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use `requests` and `BeautifulSoup` to read the contents of the HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "\n",
    "url = 'https://www.opentable.com/austin-restaurant-listings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the url we want to visit\n",
    "res = requests.get(url)\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use Beautiful Soup to convert the raw HTML into a soup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract the name of each restaurant.\n",
    "\n",
    "Let's first find each restaurant name listed on the page we've loaded. How do we find the page location of the restaurant? \n",
    "\n",
    "> *Hint: we need to know where in the **html** the restaurant element is housed.*\n",
    "\n",
    "**4.A See if you can find the restaurant name on the page. Keep in mind there are many restaurants loaded on the page.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katelynns\n",
      "Trail\n",
      "Yessenia Spring\n",
      "Gleichner Trail\n",
      "Kuphal\n",
      "Monahan\n",
      "987 Kozey\n",
      "Granville Wiegand\n",
      "Enola Weber\n",
      "Jonass\n",
      "Fannie Howell\n",
      "Fuga Pine\n",
      "Terrys\n",
      "Consequatur Walter\n",
      "Autem Mills\n",
      "Cristians\n",
      "Placeat Kuphal\n",
      "Qui Village\n",
      "Nikolaus\n",
      "Stravenue\n",
      "644 Kunze\n",
      "Crescent\n",
      "Jeanettes\n",
      "Andres\n",
      "Bartholomes\n",
      "Circle\n",
      "Russells\n",
      "Sequi\n",
      "Est Mount\n",
      "Sophies\n",
      "Valentinas\n",
      "Kerluke\n",
      "Damaris Crooks\n",
      "Stewarts\n",
      "Codys\n",
      "Natus Bergnaum\n",
      "Kiarra Tromp\n",
      "Alis\n",
      "Sint Botsford\n",
      "728 Harris\n",
      "Erna Hettinger\n",
      "Justens\n",
      "Sit\n",
      "Dolor\n",
      "Eveniet\n",
      "574 Okuneva\n",
      "Stoltenberg Key\n",
      "Est\n",
      "379 Gottlieb\n",
      "Odio\n",
      "Consequatur Circles\n",
      "Considine Hollow\n",
      "Dashawn Reynolds\n",
      "Sit\n",
      "Dach\n",
      "894 Okuneva\n",
      "Boris Expressway\n",
      "Consequatur Bartoletti\n",
      "Sammie Botsford\n",
      "Maxime\n",
      "Dollys\n",
      "Dedric Watsica\n",
      "Neque\n",
      "Repellendus Haag\n",
      "853 Mosciski\n",
      "View\n",
      "Libbies\n",
      "Agloe Bar & Grill\n",
      "Dolores Jerde\n",
      "Anastasia Gerhold\n",
      "Justens\n",
      "Autem Squares\n",
      "Trail\n",
      "Roads\n",
      "Raleighs\n",
      "Joel Cove\n",
      "Okuneva\n",
      "Quidem Coves\n",
      "843 Bode\n",
      "A Circle\n",
      "Springs\n",
      "Qui\n",
      "656 Wuckert\n",
      "Taryns\n",
      "River\n",
      "April Turner\n",
      "Wilfredo Brekke\n",
      "Lakes\n",
      "Heidenreich\n",
      "Autem Lake\n",
      "Et\n",
      "1192 Sanford\n",
      "Maude Ridge\n",
      "Mante\n",
      "Jasmin Langosh\n",
      "Colbys\n",
      "Maxie Becker\n",
      "Sydnee Bauch\n",
      "Suscipit Jones\n",
      "Inventore\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('span', {'class' : 'rest-row-name-text'}):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.B See any issues here?.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Enter Selenium - resolve the javascript issue using the driver and find the bookings. \n",
    "\n",
    "Because the page should believe I'm visiting from a live connection on a browser client, the JavaScript should render to be a part of the page source. I can then grab the page source.\n",
    "\n",
    "install selenium with `pip install selenium`\n",
    "\n",
    "\n",
    "**Once you have the HTML with the javascript rendered, repeat the processes above.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "# uncomment below for macos\n",
    "driver = webdriver.Chrome(executable_path=\"./chromedriver/macos/chromedriver\") \n",
    "\n",
    "#uncomment below for windows \n",
    "#  driver = webdriver.Chrome(executable_path=\"./chromedriver/windows/chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('http://wework.com')\n",
    "\n",
    "driver.get('https://www.opentable.com/austin-restaurant-listings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /opt/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(driver.page_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acre 41\n",
      "Rosedale Kitchen and Bar\n",
      "The Grove Wine Bar and Kitchen Downtown\n",
      "Uchiko\n",
      "Olive and June\n",
      "The Capital Grille - Austin\n",
      "34th Street Cafe\n",
      "ASTI Trattoria\n",
      "Olamaie\n",
      "The Salty Sow\n",
      "Goodall's Kitchen\n",
      "Perry's Steakhouse & Grille - Downtown Austin\n",
      "Jeffrey's Restaurant\n",
      "Josephine House\n",
      "Bar Peached\n",
      "Eddie V's - 5th Street\n",
      "Cipollina\n",
      "ALC Steaks (Austin Land & Cattle)\n",
      "Truluck's - Ocean's Finest Seafood & Crab - Austin Downtown\n",
      "ATX Cocina\n",
      "True Food Kitchen - Austin\n",
      "Roaring Fork - Downtown, Congress\n",
      "wink\n",
      "Clark's Oyster Bar\n",
      "Fixe\n",
      "Foreign & Domestic - Austin\n",
      "Dai Due\n",
      "Ranch 616\n",
      "Cafe Josie\n",
      "North Italia - Austin 2nd Street\n",
      "Carillon Restaurant\n",
      "Vince Young Steakhouse\n",
      "La Condesa\n",
      "L'Oca d'Oro\n",
      "Arlo Grey\n",
      "Eberly\n",
      "Lonesome Dove Western Bistro Austin\n",
      "Rosewood\n",
      "Bob's Steak & Chop House - Austin\n",
      "Quattro Gatti Ristorante e Pizzeria\n",
      "Caroline Restaurant\n",
      "III Forks - Austin\n",
      "Stella San Jac\n",
      "The Peacock Mediterranean Grill\n",
      "Peche Austin\n",
      "Emmer & Rye\n",
      "Il Brutto\n",
      "Le Politique\n",
      "Trace - W - Austin\n",
      "The Peached Tortilla\n",
      "Lambert's Downtown BBQ\n",
      "Fogo de Chao - Austin\n",
      "Nightcap\n",
      "The Backspace - Austin\n",
      "Ciclo\n",
      "Ruth's Chris Steak House - Austin\n",
      "Manuel's Downtown\n",
      "68 Degrees\n",
      "Colleen's Kitchen\n",
      "Oseyo\n",
      "Chez Zee\n",
      "OP Italian\n",
      "Juniper\n",
      "Parkside\n",
      "Hillside Farmacy\n",
      "RA Sushi Bar Restaurant - Austin\n",
      "Corner Restaurant\n",
      "The Russian House\n",
      "Group Therapy\n",
      "Uncle Julio's - Austin\n",
      "Cafe Blue - Downtown\n",
      "Perla's Seafood and Oyster Bar\n",
      "Soto- South\n",
      "Punch Bowl Social Austin Downtown\n",
      "Driskill Grill - Driskill Hotel\n",
      "CRÚ Food & Wine Bar - 2nd Street (Downtown Austin)\n",
      "Botticelli's\n",
      "Fleming's Steakhouse - Austin\n",
      "Vespaio Austin\n",
      "Intero Ristorante\n",
      "June's All Day\n",
      "Sushi Zushi of 5th Street\n",
      "Wu Chow\n",
      "Swift's Attic\n",
      "Thai Kitchen\n",
      "Trudys - Central\n",
      "Miltos Pizza Pub\n",
      "Hopfields\n",
      "Growlerut\n",
      "Texas French Bread\n",
      "Dirty Martins Place\n",
      "Pad Thai Cuisine\n",
      "Red Ash Italia\n",
      "Hestia\n",
      "Uchi\n",
      "Geraldine’s\n",
      "La Volpe\n",
      "P6\n",
      "Z'Tejas Austin 6th St\n",
      "Garrison\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('span', {'class' : 'rest-row-name-text'}):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Repeat the process above, and let's grab location as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downtown\n",
      "North Central\n",
      "Downtown\n",
      "Central Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Central Austin\n",
      "Midtown\n",
      "Central Austin\n",
      "East Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Central Austin\n",
      "Central Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Central Austin\n",
      "East Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Central Austin\n",
      "North Central\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "East Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "East Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Central Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Central Austin\n",
      "Central Austin\n",
      "East Austin\n",
      "Northwest\n",
      "Downtown\n",
      "East Austin\n",
      "Downtown\n",
      "East Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "East Austin\n",
      "South Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Central Austin\n",
      "Central Austin\n",
      "Central Austin\n",
      "Midtown\n",
      "Central Austin\n",
      "Central Austin\n",
      "Central Austin\n",
      "Central Austin\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n",
      "Downtown\n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('span', {'class' : 'rest-row-meta--location rest-row-meta-text sfx1388addContent'}):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Get the price for each restaurant.\n",
    "\n",
    "The price is number of dollar signs on a scale of one to four for each restaurant. We'll follow the same process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n"
     ]
    }
   ],
   "source": [
    "for i in soup.find_all('i', {'class' : 'pricing--the-price'}):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.B Convert the dollar sign strings to a count of the number of dollar signs.**\n",
    "\n",
    "Can you figure out a way to simply print out the number of dollar signs per restaurant listed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    $  \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    $  \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $    $    \n",
      "  $    $      \n",
      "  $    $      \n",
      "  $    $    $    \n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "for i in soup.find_all('i', {'class' : 'pricing--the-price'}):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Can you find the number of times a restaurant was booked.\n",
    "\n",
    "In the next cell, print out a sample of objects that contain the number of times the restaurant was booked.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Booked 19 times today\n",
      " Booked 28 times today\n",
      " Booked 12 times today\n",
      " Booked 77 times today\n",
      " Booked 17 times today\n",
      " Booked 37 times today\n",
      " Booked 5 times today\n",
      " Booked 9 times today\n",
      " Booked 37 times today\n",
      " Booked 52 times today\n",
      " Booked 2 times today\n",
      " Booked 65 times today\n",
      " Booked 31 times today\n",
      " Booked 41 times today\n",
      " Booked 16 times today\n",
      " Booked 70 times today\n",
      " Booked 19 times today\n",
      " Booked 14 times today\n",
      " Booked 50 times today\n",
      " Booked 81 times today\n",
      " Booked 55 times today\n",
      " Booked 48 times today\n",
      " Booked 8 times today\n",
      " Booked 36 times today\n",
      " Booked 35 times today\n",
      " Booked 19 times today\n",
      " Booked 25 times today\n",
      " Booked 29 times today\n",
      " Booked 12 times today\n",
      " Booked 43 times today\n",
      " Booked 7 times today\n",
      " Booked 15 times today\n",
      " Booked 30 times today\n",
      " Booked 19 times today\n",
      " Booked 22 times today\n",
      " Booked 47 times today\n",
      " Booked 13 times today\n",
      " Booked 11 times today\n",
      " Booked 14 times today\n",
      " Booked 3 times today\n",
      " Booked 27 times today\n",
      " Booked 28 times today\n",
      " Booked 31 times today\n",
      " Booked 61 times today\n",
      " Booked 20 times today\n",
      " Booked 41 times today\n",
      " Booked 22 times today\n",
      " Booked 19 times today\n",
      " Booked 13 times today\n",
      " Booked 24 times today\n",
      " Booked 26 times today\n",
      " Booked 33 times today\n",
      " Booked 2 times today\n",
      " Booked 9 times today\n",
      " Booked 6 times today\n",
      " Booked 17 times today\n",
      " Booked 19 times today\n",
      " Booked 11 times today\n",
      " Booked 9 times today\n",
      " Booked 27 times today\n",
      " Booked 12 times today\n",
      " Booked 15 times today\n",
      " Booked 26 times today\n",
      " Booked 10 times today\n",
      " Booked 19 times today\n",
      " Booked 15 times today\n",
      " Booked 47 times today\n",
      " Booked 11 times today\n",
      " Booked 3 times today\n",
      " Booked 18 times today\n",
      " Booked 9 times today\n",
      " Booked 57 times today\n",
      " Booked 8 times today\n",
      " Booked 13 times today\n",
      " Booked 1 times today\n",
      " Booked 3 times today\n",
      " Booked 20 times today\n",
      " Booked 5 times today\n",
      " Booked 20 times today\n",
      " Booked 15 times today\n",
      " Booked 25 times today\n",
      " Booked 45 times today\n",
      " Booked 28 times today\n",
      " Booked 58 times today\n",
      " Booked 44 times today\n",
      " Booked 89 times today\n",
      " Booked 32 times today\n",
      " Booked 9 times today\n",
      " Booked 16 times today\n",
      " Booked 4 times today\n"
     ]
    }
   ],
   "source": [
    "# A:\n",
    "for i in soup.find_all('div', {'class' : 'booking'}):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Can we get all of the items we want from the page in a single `find_all`?\n",
    "\n",
    "To be most efficient, we want to only do a single loop for each entry on the page. That means we want to find what element all of other other elements (name, location, price, bookings) is housed within. Where on the page is each entry located?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>location</th>\n",
       "      <th>price</th>\n",
       "      <th>bookings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acre 41</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rosedale Kitchen and Bar</td>\n",
       "      <td>North Central</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Grove Wine Bar and Kitchen Downtown</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Uchiko</td>\n",
       "      <td>Central Austin</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Olive and June</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Geraldine’s</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>La Volpe</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>P6</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Z'Tejas Austin 6th St</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Garrison</td>\n",
       "      <td>Downtown</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       name        location price bookings\n",
       "0                                   acre 41        Downtown     2       19\n",
       "1                  Rosedale Kitchen and Bar   North Central     2       28\n",
       "2   The Grove Wine Bar and Kitchen Downtown        Downtown     2       12\n",
       "3                                    Uchiko  Central Austin     3       77\n",
       "4                            Olive and June        Downtown     3       17\n",
       "..                                      ...             ...   ...      ...\n",
       "95                              Geraldine’s        Downtown     3       32\n",
       "96                                 La Volpe        Downtown     3        9\n",
       "97                                       P6        Downtown     2       16\n",
       "98                    Z'Tejas Austin 6th St        Downtown     2        0\n",
       "99                                 Garrison        Downtown     3        4\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=['name', 'location', 'price', 'bookings'])\n",
    "for row in soup.find_all('div', {'class':'rest-row-info'}):\n",
    "    name = row.find('span', {'class':'rest-row-name-text'}).text\n",
    "    location = row.find('span', {'class':'rest-row-meta--location'}).text\n",
    "    p = row.find('i', {'class': 'pricing--the-price'})\n",
    "    price = p.text.count('$')\n",
    "    try:\n",
    "        bookings = row.find('div', {'class': 'booking'}).text.split()[1]\n",
    "    except:\n",
    "        bookings = '0'\n",
    "    df.loc[len(df)] = [name, location, price, bookings]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Does every single entry have each element we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Use python exceptions to handle cases when bookings aren't found.\n",
    "\n",
    "When a booking is not found, store 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Putting it all together in a dataframe.\n",
    "\n",
    "**Loop through each entry. For each entry:**\n",
    "1. Grab the relevant information we want (name, location, price, bookings). \n",
    "2. Produce a dataframe with the columns \"name\",\"location\",\"price\",\"bookings\" that contains the 100 entries we would like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## add together all the pieces here \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Use selenium to loop through at least 5 pages and grab that information as well. Chicago is a good example of a city with enough restaurant listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "---\n",
    "\n",
    "The above example (and many others) are available in the Selenium docs: http://selenium-python.readthedocs.io/getting-started.html\n",
    "\n",
    "What is especially important is exploring functionality like locating elements: http://selenium-python.readthedocs.io/locating-elements.html#locating-elements\n",
    "\n",
    "FAQ:\n",
    "http://selenium-python.readthedocs.io/faq.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

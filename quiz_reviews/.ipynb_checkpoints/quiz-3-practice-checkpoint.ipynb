{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Quiz 3 In-Class Review\n",
    "\n",
    " _**Authors:** Boom D. (DSI-NYC), J Beightol (DSI-ATX)_ \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1.** Briefly explain why Linear Regression is not an appropriate method for predicting a $Y$ that is discrete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discrete values are specific which are more appropriate for classification, between 0 and 1 predictions/percentage.\n",
    "Continuous values have a wide range which works great for Linear Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2.** Suppose $Y$ is a binary variable that takes a value of $Y = 1$ if a person is at-risk of heart disease, and $Y = 0$ otherwise. Also let $X_1$ = LDL Cholesterol level and $X_2$ = binary variable for whether or not a person smokes. A scientist decides to construct the following regression model:\n",
    "\n",
    "$$ \\text{log}(\\frac{P(Y = 1)}{1 - P(Y = 1)}) = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 $$\n",
    "\n",
    "After fitting the model with data, the scientist finds that $\\beta_1 = 5.8$\n",
    "\n",
    "What is one appropriate interpretation for the impact of LDL Cholesterol level on the chances of developing heart-disease?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every 1 unit increase in LDL, a person is e^5.8% as likely to meet criteria 1, in this example, develop heart disease.\n",
    "This is a very large coefficient for LogReg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3.** $k$-Nearest Neighbors ($k$NN) is a classification algorithm where $k$ is a hyperparameter. Briefly state what $k$ represents and its role in how the $k$NN algorithm works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K represents the amount of neighbors in the algorithm. Imagine that all your data points are being represented visually on a graphy. The algorithm will predict the classification of a data point based on the classification of its 'nearest neighbors' on the graph. If k = 1, the prediction will be based on its 1 closest neighbor, if k = 3 the prediction will be based on the majority of the 3 closest neighbors. There is an optimal value of k, but as K increases bias increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics: Confusion Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is 2190 and an evil dictator has decided that the justice system should be completely automated by an classification algorithm of his own design that decides whether someone is guilty. Out of 100,000 people sampled, his model has made the following results:\n",
    "- 63,000 truly guilty people were predicted to be guilty\n",
    "- 27,000 truly innocent people were predicted to be guilty\n",
    "- 3,000 truly guilty people were predicted to be innocent\n",
    "- 7,000 truly innocent people were predicted to be innocent\n",
    "\n",
    "**It's recommended that you create a confusion matrix to answer the following questions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4.** State the number of **false positive** and **false negative** predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27,000 false positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3,000 false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-434b98aaa143>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m cm_df = pd.DataFrame(cm, columns=['Predicted No CKD', 'Predicted CKD'],\n\u001b[0m\u001b[1;32m      2\u001b[0m                          index = ['Actual No CKD', 'Actual CKD'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm, columns=['Predicted No CKD', 'Predicted CKD'],\n",
    "                         index = ['Actual No CKD', 'Actual CKD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted 63000, predicted 27000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5.** Calculate the following metrics\n",
    "    - Accuracy Rate\n",
    "    - Misclassification Rate\n",
    "    - Sensitivity\n",
    "    - Specificity\n",
    "    - Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "63000 / 90000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20588235294117646"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7000 / 34000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy Rate = \n",
    "Misclassification Rate = \n",
    "Sensitivity = 90,000 Truly Guilty, 70% correctly identified\n",
    "Specificity = 34,000 Truly Innocent, 20.56% correctly identified\n",
    "Precision = "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Classification Metrics: AUC ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that\n",
    "- Sensitivity : Out of all the Y = 1 (Guilty) observations, how many did we correctly identify?\n",
    "- Specificity : Out of all the Y = 0 (Innocent) observations, how many did we correctly Identify?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6.** Which of these is also known as the True Positive Rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sensitivity, also Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7.** While we don't explicitly have a unique name for the False Positive Rate, write an expression for the **False Positive Rate** using one of the above metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False Positive Rate:\n",
      "0.7941176470588235\n"
     ]
    }
   ],
   "source": [
    "print('False Positive Rate:')\n",
    "print(27000 / 34000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misclassification Rate has 27,000 false positives, which is 30%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q8.** If we predict \"guilty\" for all observations, what happens to:\n",
    "- Sensitivity\n",
    "- Specificity\n",
    "- False Positive Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect Sensitivity\n",
    "Specificity goes down to 0%.\n",
    "False Positive Rate goes up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q9. (True/False)** The Receiver Operator Characteristic (ROC) curve shows the trade-off between the True Positive Rate and False Positive Rate. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a visual for how the ROC curve is constructed from the data, check this out: http://mlwiki.org/index.php/ROC_Analysis#Example_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q10.**  At the start of the ROC curve (**bottom** left), are we predicting positives for all observations or negatives for all observations? What about the end of the ROC curve (top right)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lower left is all negatives, upper right is all positives, then you have a middle in between balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q11.** What range of values can AUC ROC scores take on?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q12.** How would you handle a case where $0 \\le AUC ROC < 0.5$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predicted values are less than baseline values, you are finding negative signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q13.** A student is trying to optimize a model by tuning hyperparameters with `GridSearchCV()`. She runs the following code to do so.\n",
    "\n",
    "```python\n",
    "params = {'C':       [0.01, 0.02, 0.1, 1, 10, 50, 100],\n",
    "          'penalty': ['l1', 'l2']}\n",
    "logit = GridSearchCV(LogisticRegression(), cv=5, param_grid=params)\n",
    "logit.fit(X_train, y_train)\n",
    "C_optimal = logit.best_params_['C']\n",
    "```\n",
    "How many model fit simulations does the above code run behind the scenes before arriving at the optimal hyperparameter combinations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7 * 2 * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing (NLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q14.** Briefly discuss (preferably with an example case) why it may not always be optimal to always tokenize a string into single words only, i.e. why `ngram_range = (1,1)` is not always ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenization what features to include.\n",
    "First and last names as an example, when 2 words are meant to stay together, 'not good', words that rely on the word before it and the word after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q15.** Briefly explain the adjustment `TFIDFVectorizer()` makes to `CountVectorizer()` and describe why we may sometimes prefer TFIDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer gets a raw count of the words.\n",
    "TFIDF scores the word based on its scarcity. The rarer a word, the higher the score. This is all within the Corpus, which is a collection of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
